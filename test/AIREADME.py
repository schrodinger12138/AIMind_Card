import os
import json
import re
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""

    def __init__(self, model="gpt-3.5-turbo"):
        api_key = os.environ.get("OPENAI_API_KEY", "sk-lwkQzJYwYdJwbQ4DaAlM3Ti6pgMCzEgztBjREyOlYFPLPDQP")
        if not api_key:
            raise RuntimeError("æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·å…ˆè®¾ç½®APIå¯†é’¥")

        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.chatanywhere.tech/v1"
        )
        self.model = model
        self.lock = threading.Lock()
    
    def analyze_code(self, file_path, code_content):
        """åˆ†æPythonä»£ç 
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            code_content: ä»£ç å†…å®¹
            
        Returns:
            dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹Pythonä»£ç ï¼Œæä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚ä»£ç æ¥è‡ªæ–‡ä»¶: {file_path}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
- function_summary: ä¸»è¦å‡½æ•°/æ–¹æ³•çš„ç®€è¦è¯´æ˜
- key_features: ä»£ç çš„æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
- complexity_analysis: ä»£ç å¤æ‚åº¦åˆ†æï¼ˆç®€å•/ä¸­ç­‰/å¤æ‚ï¼‰
- improvement_suggestions: æ”¹è¿›å»ºè®®ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰
- potential_issues: æ½œåœ¨é—®é¢˜æˆ–é£é™©ç‚¹ï¼ˆåˆ—è¡¨å½¢å¼ï¼‰

ä»£ç å†…å®¹ï¼š
{code_content[:4000]}  # é™åˆ¶å†…å®¹é•¿åº¦
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†æPythonä»£ç çš„ç»“æ„ã€åŠŸèƒ½å’Œä¼˜åŒ–ç‚¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.2
            )
            
            result_text = (response.choices[0].message.content or "").strip()
            
            # è§£æJSONå“åº”
            analysis_data = self._parse_json_response(result_text)
            
            # æ„å»ºåˆ†æç»“æœ
            analysis_result = {
                "file_path": file_path,
                "function_summary": analysis_data.get("function_summary", "æ— æ€»ç»“"),
                "key_features": analysis_data.get("key_features", []),
                "complexity_analysis": analysis_data.get("complexity_analysis", "æœªçŸ¥"),
                "improvement_suggestions": analysis_data.get("improvement_suggestions", []),
                "potential_issues": analysis_data.get("potential_issues", [])
            }
            
            with self.lock:
                print(f"âœ… å·²å®Œæˆåˆ†æ: {file_path}")
            
            return analysis_result
            
        except Exception as e:
            with self.lock:
                print(f"âŒ åˆ†æå¤±è´¥ {file_path}: {str(e)}")
            
            return {
                "file_path": file_path,
                "function_summary": f"åˆ†æå¤±è´¥: {str(e)}",
                "key_features": [],
                "complexity_analysis": "æœªçŸ¥",
                "improvement_suggestions": [],
                "potential_issues": []
            }
    
    def _parse_json_response(self, response_text):
        """è§£æAIè¿”å›çš„JSONå“åº”"""
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            else:
                return {
                    "function_summary": "JSONè§£æå¤±è´¥",
                    "key_features": ["æ— æ³•è§£æAIå“åº”"],
                    "complexity_analysis": "æœªçŸ¥",
                    "improvement_suggestions": ["æ£€æŸ¥AIå“åº”æ ¼å¼"],
                    "potential_issues": ["AIå“åº”æ ¼å¼å¼‚å¸¸"]
                }

def merge_py_to_markdown(root_dir, max_workers=3):
    """åˆå¹¶Pythonæ–‡ä»¶å¹¶ç”Ÿæˆä»£ç åˆ†ææŠ¥å‘Šï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
    
    # åˆå§‹åŒ–ä»£ç åˆ†æå™¨
    analyzer = CodeAnalyzer()
    
    # ç›®æ ‡ Markdown æ–‡ä»¶è·¯å¾„
    output_dir = os.path.join(root_dir, "")
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "AI_code_analysis.md")

    # æ”¶é›†æ‰€æœ‰Pythonæ–‡ä»¶
    python_files = []
    for dirpath, _, filenames in os.walk(root_dir):
        if os.path.abspath(dirpath) == os.path.abspath(output_dir):
            continue
        for file in filenames:
            if file.endswith(".py"):
                filepath = os.path.join(dirpath, file)
                rel_path = os.path.relpath(filepath, root_dir)
                python_files.append((rel_path, filepath))

    print(f"ğŸ” æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")

    # å¤šçº¿ç¨‹åˆ†ææ–‡ä»¶
    analysis_results = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {}
        for rel_path, filepath in python_files:
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    code_content = f.read()
                
                # è·³è¿‡ç©ºæ–‡ä»¶æˆ–è¿‡å°çš„æ–‡ä»¶
                if len(code_content.strip()) < 10:
                    continue
                
                # æäº¤åˆ†æä»»åŠ¡
                future = executor.submit(analyzer.analyze_code, rel_path, code_content)
                future_to_file[future] = (rel_path, filepath, code_content)
                
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {rel_path}: {e}")

        # æ”¶é›†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_file):
            rel_path, filepath, code_content = future_to_file[future]
            try:
                result = future.result()
                analysis_results.append((rel_path, filepath, code_content, result))
            except Exception as e:
                print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {rel_path}: {e}")

    # æŒ‰æ–‡ä»¶è·¯å¾„æ’åºç»“æœ
    analysis_results.sort(key=lambda x: x[0])

    # ç”ŸæˆMarkdownæŠ¥å‘Š
    with open(output_file, "w", encoding="utf-8") as out:
        out.write("# AIä»£ç åˆ†ææŠ¥å‘Š\n\n")
        out.write("> æœ¬æ–‡æ¡£ç”±AIè‡ªåŠ¨åˆ†æé¡¹ç›®ä¸­çš„Pythonä»£ç å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š\n\n")
        out.write(f"## é¡¹ç›®æ¦‚è§ˆ\n\n")
        out.write(f"- **åˆ†ææ–‡ä»¶æ•°**: {len(analysis_results)}\n")
        out.write(f"- **åˆ†ææ—¶é—´**: {os.path.basename(root_dir)}\n")
        out.write(f"- **ä½¿ç”¨æ¨¡å‹**: GPT-3.5-turbo\n\n")
        out.write("---\n\n")

        for rel_path, filepath, code_content, analysis in analysis_results:
            out.write(f"## ğŸ“„ æ–‡ä»¶: {rel_path}\n\n")
            
            # åŠŸèƒ½æ€»ç»“
            out.write(f"### ğŸ“‹ åŠŸèƒ½æ€»ç»“\n\n")
            out.write(f"{analysis['function_summary']}\n\n")
            
            # å¤æ‚åº¦åˆ†æ
            out.write(f"### ğŸ¯ å¤æ‚åº¦åˆ†æ\n\n")
            complexity = analysis['complexity_analysis']
            complexity_emoji = "ğŸŸ¢" if "ç®€å•" in complexity else "ğŸŸ¡" if "ä¸­ç­‰" in complexity else "ğŸ”´"
            out.write(f"{complexity_emoji} **{complexity}**\n\n")
            
            # æ ¸å¿ƒç‰¹æ€§
            out.write(f"### âœ¨ æ ¸å¿ƒç‰¹æ€§\n\n")
            features = analysis['key_features']
            if features:
                for feature in features:
                    out.write(f"- {feature}\n")
            else:
                out.write("- æ— æ˜ç¡®ç‰¹æ€§æ ‡è¯†\n")
            out.write("\n")
            
            # æ”¹è¿›å»ºè®®
            out.write(f"### ğŸ’¡ æ”¹è¿›å»ºè®®\n\n")
            suggestions = analysis['improvement_suggestions']
            if suggestions:
                for suggestion in suggestions:
                    out.write(f"- ğŸ“ {suggestion}\n")
            else:
                out.write("- æš‚æ— æ”¹è¿›å»ºè®®\n")
            out.write("\n")
            
            # æ½œåœ¨é—®é¢˜
            out.write(f"### âš ï¸ æ½œåœ¨é—®é¢˜\n\n")
            issues = analysis['potential_issues']
            if issues:
                for issue in issues:
                    out.write(f"- ğŸ” {issue}\n")
            else:
                out.write("- æœªå‘ç°æ˜æ˜¾é—®é¢˜\n")
            out.write("\n")
            
            # æºä»£ç ï¼ˆå¯æŠ˜å ï¼‰
            out.write("<details>\n<summary>ğŸ“ æŸ¥çœ‹æºä»£ç </summary>\n\n")
            out.write("```python\n")
            out.write(code_content)
            out.write("\n```\n")
            out.write("</details>\n\n")
            
            out.write("---\n\n")

    print(f"âœ… AIä»£ç åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    print(f"ğŸ“Š æˆåŠŸåˆ†æ {len(analysis_results)} ä¸ªæ–‡ä»¶")

def analyze_single_file(file_path):
    """å•ç‹¬åˆ†æä¸€ä¸ªPythonæ–‡ä»¶"""
    analyzer = CodeAnalyzer()
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            code_content = f.read()
        
        print(f"æ­£åœ¨åˆ†æ: {file_path}")
        result = analyzer.analyze_code(file_path, code_content)
        
        print(f"\nğŸ“„ æ–‡ä»¶: {file_path}")
        print(f"ğŸ“‹ åŠŸèƒ½æ€»ç»“: {result['function_summary']}")
        print(f"ğŸ¯ å¤æ‚åº¦: {result['complexity_analysis']}")
        print(f"âœ¨ æ ¸å¿ƒç‰¹æ€§: {', '.join(result['key_features'][:3])}")
        print(f"ğŸ’¡ æ”¹è¿›å»ºè®®: {', '.join(result['improvement_suggestions'][:2])}")
        print(f"âš ï¸ æ½œåœ¨é—®é¢˜: {', '.join(result['potential_issues'][:2])}")
        print("-" * 50)
        
        return result
        
    except Exception as e:
        print(f"âŒ åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return None

# ä½¿ç”¨æ–¹æ³•
if __name__ == "__main__":
    root = r"E:\onedrive\OneDrive - bupt.edu.cn\AIcard"  # â† ä¿®æ”¹ä¸ºä½ çš„ä¸»ç›®å½•è·¯å¾„
    
    # ç”Ÿæˆå®Œæ•´çš„AIä»£ç åˆ†ææŠ¥å‘Šï¼ˆå¤šçº¿ç¨‹ï¼Œ3ä¸ªworkerï¼‰
    merge_py_to_markdown(root, max_workers=3)
    
    # å¦‚æœéœ€è¦å•ç‹¬åˆ†ææŸä¸ªæ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ï¼š
    # single_file = r"C:\Users\anyon\pythonProject\example.py"
    # analyze_single_file(single_file)